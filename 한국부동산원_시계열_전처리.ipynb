{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9a4cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다운로드 디렉터리를 입력하세요:  C:/Users/Administrator/Downloads\n",
      "루트 폴더 경로를 입력하세요:  H:/파이썬코드모음/시계열다루기\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "R1주간아파트가격시계열통계전처리작업시작\n",
      "24.8월 1주 주간아파트가격동향조사 시계열.xlsx\n",
      "r1_week가져오기\n",
      "지역명_API테이블 가져오기\n",
      "시계열&지역명 VLOOKUP작업1\n",
      "시계열&지역명 VLOOKUP작업2\n",
      "시계열&지역명 VLOOKUP작업3\n",
      "R1주간아파트가격시계열통계전처리작업종료\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# download_directory = \"C:/Users/Administrator/Downloads\"\n",
    "# root_folder = \"H:/파이썬코드모음/시계열다루기\"\n",
    "\n",
    "# 폴더경로 입력받기\n",
    "download_directory = input(\"다운로드 디렉터리를 입력하세요: \")\n",
    "root_folder = input(\"루트 폴더 경로를 입력하세요: \")\n",
    "print(\"\")\n",
    "r1_region_2 = f\"{root_folder}/r1_region.json\"\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"R1주간아파트가격시계열통계전처리작업시작\")\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "driver = webdriver.Chrome(service=Service(), options=options)\n",
    "\n",
    "\n",
    "if download_directory == \"default\":\n",
    "    최초다운로드 = os.path.join(os.path.expanduser(\"~\"), \"Downloads/\")  # 파일들이 들어있는 폴더\n",
    "else:\n",
    "    최초다운로드 = f\"{download_directory}/\"\n",
    "\n",
    "시계열파일이동할곳 = f\"{root_folder}\"\n",
    "\n",
    "###############폴더만들기##############\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Creating directory. \" + directory)\n",
    "\n",
    "createFolder(시계열파일이동할곳)\n",
    "###############폴더만들기##############\n",
    "\n",
    "driver.get(\n",
    "    \"https://www.reb.or.kr/r-one/na/ntt/selectNttList.do?mi=9509&bbsId=1106\"\n",
    ")\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "file = 최초다운로드 + \"/r1_week.xlsx\"\n",
    "\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# 가장최근파일가져오기\n",
    "fileEx = r\".xlsx\"\n",
    "file_name_and_time_lst = []\n",
    "# 해당 경로에 있는 파일들의 생성시간을 함께 리스트로 넣어줌.\n",
    "for f_name in os.listdir(f\"{최초다운로드}\"):\n",
    "    if f_name.endswith(fileEx):\n",
    "        written_time = os.path.getctime(f\"{최초다운로드}{f_name}\")\n",
    "        file_name_and_time_lst.append((f_name, written_time))\n",
    "# 생성시간 역순으로 정렬하고,\n",
    "sorted_file_lst = sorted(\n",
    "    file_name_and_time_lst, key=lambda x: x[1], reverse=True\n",
    ")\n",
    "# 가장 앞에 있는 것을 넣어준다.\n",
    "# print(file_name_and_time_lst)\n",
    "recent_file = sorted_file_lst[0]\n",
    "recent_file_name = recent_file[0]\n",
    "\n",
    "# print(recent_file)\n",
    "print(recent_file_name)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# 파일이름변경\n",
    "os.rename(f\"{최초다운로드}/{recent_file_name}\", f\"{최초다운로드}/r1_week.xlsx\")\n",
    "\n",
    "###############폴더내파일삭제##############\n",
    "file = 시계열파일이동할곳 + \"/r1_week.xlsx\"\n",
    "\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "###############폴더내파일삭제##############\n",
    "\n",
    "\n",
    "# 예시\n",
    "shutil.move(f\"{최초다운로드}/r1_week.xlsx\", 시계열파일이동할곳)\n",
    "############################한국부동산원주간시계열################################\n",
    "driver.close()\n",
    "\n",
    "######################################################################\n",
    "\n",
    "# 파일이름 나열하기\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "###################r1_week가져오기#################################\n",
    "print(\"r1_week가져오기\")\n",
    "file_path = f\"{root_folder}/r1_week.xlsx\"\n",
    "\n",
    "def r1_week(name):\n",
    "    df = pd.read_excel(file_path, sheet_name=name)  # for구문으로 csv파일들을 읽어 들인다\n",
    "\n",
    "    # index가 0인 행만 삭제\n",
    "    # df = df.drop(index=0, axis=0)\n",
    "\n",
    "    # index가 0,1,2인 행 삭제\n",
    "    df = df.drop(index=[0, 1, 2, 3], axis=0)\n",
    "\n",
    "    #     df\n",
    "    header = df.iloc[0]\n",
    "    # print(header)\n",
    "\n",
    "    header = []\n",
    "    for i in range(0, 236):\n",
    "        header.append(i)\n",
    "    # print(header)\n",
    "    df = df[df[\"Unnamed: 7\"].notna()]\n",
    "\n",
    "    df.columns = header\n",
    "    df\n",
    "\n",
    "    value_vars = []\n",
    "    for i in range(0, 236):\n",
    "        value_vars.append(i)\n",
    "\n",
    "    df = df.melt(id_vars=0, value_vars=value_vars)\n",
    "\n",
    "    df = df.astype({\"value\": \"float32\"})\n",
    "\n",
    "    df.rename(\n",
    "        columns={0: \"ymd\", \"variable\": \"index\", \"value\": name}, inplace=True\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "data_list = [\n",
    "    r1_week(\"매매변동률\"),\n",
    "    r1_week(\"전세변동률\"),\n",
    "    r1_week(\"매매지수\"),\n",
    "    r1_week(\"전세지수\"),\n",
    "]\n",
    "\n",
    "r1_week = reduce(\n",
    "    lambda x, y: pd.merge(x, y, on=[\"ymd\", \"index\"], how=\"outer\"), data_list\n",
    ")\n",
    "\n",
    "# ymd오름차순!!!!!\n",
    "r1_week = r1_week.sort_values(by=[\"ymd\", \"index\"])\n",
    "\n",
    "r1_week\n",
    "###################r1_week가져오기#################################\n",
    "\n",
    "###################지역명_API가져오기#################################\n",
    "print(\"지역명_API테이블 가져오기\")\n",
    "\n",
    "# DataFrame 생성 및 출력\n",
    "region_api = pd.read_json(r1_region_2)\n",
    "region_api\n",
    "\n",
    "region_api.columns\n",
    "columns = list(region_api.columns)\n",
    "# print(columns)\n",
    "\n",
    "# region_api.info()\n",
    "\n",
    "region_api.astype(\"str\")\n",
    "\n",
    "region_api[\"area_code\"] = region_api[\"area_code\"].fillna(0)\n",
    "\n",
    "region_api = region_api.astype({\"area_code\": \"str\"})\n",
    "\n",
    "region_api[\"area_code2\"] = region_api[\"area_code2\"].fillna(0)\n",
    "\n",
    "region_api = region_api.astype({\"area_code2\": \"str\"})\n",
    "\n",
    "region_api[\"area_code4\"] = region_api[\"area_code4\"].fillna(0)\n",
    "\n",
    "region_api = region_api.astype({\"area_code4\": \"str\"})\n",
    "\n",
    "region_api[\"area_code5\"] = region_api[\"area_code5\"].fillna(0)\n",
    "\n",
    "region_api = region_api.astype({\"area_code5\": \"str\"})\n",
    "\n",
    "# 176개지역 필터링하기\n",
    "# region_api = region_api[(region_api['gubun']== 1)|(region_api['gubun']== 13)]\n",
    "\n",
    "# region_api.info()\n",
    "\n",
    "region_api\n",
    "# ###################지역명_API가져오기#################################\n",
    "\n",
    "###################두테이블조인하기##################################\n",
    "# print(\"기존 시세테이블(mama4)과 region_api테이블 병합\")\n",
    "print(\"시계열&지역명 VLOOKUP작업1\")\n",
    "\n",
    "r1_week = pd.merge(\n",
    "    left=r1_week,\n",
    "    right=region_api,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"index\"],\n",
    "    right_on=[\"index\"],\n",
    "    sort=False,\n",
    ")\n",
    "\n",
    "r1_week = r1_week.astype({\"gubun\": \"int64\"})\n",
    "\n",
    "r1_week\n",
    "###################두테이블조인하기##################################\n",
    "\n",
    "###################시군구매매증감전세증감순위매기기##################################\n",
    "series = r1_week.copy()[\n",
    "    (r1_week.copy()[\"gubun\"] == 3) | (r1_week.copy()[\"gubun\"] == 13)\n",
    "]\n",
    "series\n",
    "\n",
    "series[\"매매증감순위1\"] = (\n",
    "    series.copy().groupby([\"ymd\"])[\"매매변동률\"].rank(method=\"min\", ascending=False)\n",
    ")\n",
    "series[\"전세증감순위1\"] = (\n",
    "    series.copy().groupby([\"ymd\"])[\"전세변동률\"].rank(method=\"min\", ascending=False)\n",
    ")\n",
    "series = series[[\"ymd\", \"area_code2\", \"매매증감순위1\", \"전세증감순위1\"]]\n",
    "###################시군구매매증감전세증감순위매기기##################################\n",
    "\n",
    "###################두테이블조인하기##################################\n",
    "# print(\"기존 시세테이블(mama4)과 region_api테이블 병합\")\n",
    "print(\"시계열&지역명 VLOOKUP작업2\")\n",
    "\n",
    "r1_week1 = pd.merge(\n",
    "    left=r1_week,\n",
    "    right=series,\n",
    "    how=\"left\",\n",
    "    left_on=[\"ymd\", \"area_code2\"],\n",
    "    right_on=[\"ymd\", \"area_code2\"],\n",
    "    sort=False,\n",
    ")\n",
    "\n",
    "r1_week1\n",
    "###################두테이블조인하기##################################\n",
    "\n",
    "###################시도매매증감전세증감순위매기기##################################\n",
    "series1 = r1_week.copy()[\n",
    "    (r1_week.copy()[\"gubun\"] == 1) | (r1_week.copy()[\"gubun\"] == 13)\n",
    "]\n",
    "series1\n",
    "\n",
    "series1[\"매매증감순위2\"] = (\n",
    "    series1.copy().groupby([\"ymd\"])[\"매매변동률\"].rank(method=\"min\", ascending=False)\n",
    ")\n",
    "series1[\"전세증감순위2\"] = (\n",
    "    series1.copy().groupby([\"ymd\"])[\"전세변동률\"].rank(method=\"min\", ascending=False)\n",
    ")\n",
    "series1 = series1[[\"ymd\", \"index\", \"매매증감순위2\", \"전세증감순위2\"]]\n",
    "###################시도매매증감전세증감순위매기기##################################\n",
    "\n",
    "###################두테이블조인하기##################################\n",
    "# print(\"기존 시세테이블(mama4)과 region_api테이블 병합\")\n",
    "print(\"시계열&지역명 VLOOKUP작업3\")\n",
    "\n",
    "r1_week2 = pd.merge(\n",
    "    left=r1_week1,\n",
    "    right=series1,\n",
    "    how=\"left\",\n",
    "    left_on=[\"ymd\", \"index\"],\n",
    "    right_on=[\"ymd\", \"index\"],\n",
    "    sort=False,\n",
    ")\n",
    "\n",
    "r1_week2\n",
    "r1_week2.rename(\n",
    "    columns={\n",
    "        \"매매변동률\": \"m_dt\",\n",
    "        \"전세변동률\": \"j_dt\",\n",
    "        \"매매지수\": \"m_js\",\n",
    "        \"전세지수\": \"j_js\",\n",
    "        \"매매증감순위1\": \"m_dt_rank1\",\n",
    "        \"전세증감순위1\": \"j_dt_rank1\",\n",
    "        \"매매증감순위2\": \"m_dt_rank2\",\n",
    "        \"전세증감순위2\": \"j_dt_rank2\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "r1_week2 = r1_week2.sort_index(axis=1)\n",
    "###################두테이블조인하기##################################\n",
    "r1_week2.to_csv(\n",
    "    f\"{root_folder}/r1_week.csv\", encoding=\"utf-8-sig\", index=False\n",
    ")\n",
    "###################두테이블조인하기##################################\n",
    "print(\"R1주간아파트가격시계열통계전처리작업종료\")\n",
    "print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4281f2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Downloading numpy-2.0.1-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 11.6/11.6 MB 60.4 MB/s eta 0:00:00\n",
      "Downloading numpy-2.0.1-cp310-cp310-win_amd64.whl (16.6 MB)\n",
      "   ---------------------------------------- 0.0/16.6 MB ? eta -:--:--\n",
      "   ---------------------------------------  16.5/16.6 MB 80.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.6/16.6 MB 41.7 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.0.1 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d730de-03b4-46bb-965a-4c80c9c31ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.23.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from selenium) (2024.7.4)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from trio~=0.17->selenium) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.23.1-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  9.4/9.4 MB 53.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 30.9 MB/s eta 0:00:00\n",
      "Downloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
      "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, pysocks, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.23.1 sortedcontainers-2.4.0 trio-0.26.2 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d44580b-af1a-4607-bfbc-6d24638c98a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from webdriver_manager) (2.32.3)\n",
      "Collecting python-dotenv (from webdriver_manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from webdriver_manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from requests->webdriver_manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from requests->webdriver_manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from requests->webdriver_manager) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\envs\\reals\\lib\\site-packages (from requests->webdriver_manager) (2024.7.4)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver_manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver_manager-4.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a506ae7c-19e1-4e5e-8dc3-4ba102b4ad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
